{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lending Club wants to understand the driving factors (or driver variables) behind loan default, i.e. the variables which are strong indicators of default.  The company can utilise this knowledge for its portfolio and risk assessment.  \n",
    "Two types of risks are associated with the bank’s decision:  \n",
    "\n",
    "* If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company  \n",
    "\n",
    "* If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company  \n",
    "  \n",
    "The provided data contains the information about past loan applicants and whether they ‘defaulted’ or not. The aim is to identify patterns which indicate if a person is likely to default, which may be used for taking actions such as denying the loan, reducing the amount of loan, lending (to risky applicants) at a higher interest rate, etc.  \n",
    "  \n",
    "When a person applies for a loan, there are two types of decisions that could be taken by the company:  \n",
    "\n",
    "1. Loan accepted: If the company approves the loan, there are 3 possible scenarios described below:\n",
    "\n",
    " * Fully paid: Applicant has fully paid the loan (the principal and the interest rate)\n",
    "\n",
    " * Current: Applicant is in the process of paying the instalments, i.e. the tenure of the loan is not yet completed. These candidates are not labelled as 'defaulted'.\n",
    "\n",
    " * Charged-off: Applicant has not paid the instalments in due time for a long period of time, i.e. he/she has defaulted on the loan \n",
    "\n",
    "2. Loan rejected: The company had rejected the loan (because the candidate does not meet their requirements etc.). This data is not part of provided data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.libqsturng import psturng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the data from loan.csv file. While doing so low_memory is set to False to avoide mixed data type warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan data, low_memory set to False to avoide mixed data type warning\n",
    "loan_all_df = pd.read_csv(\"loan.csv\", low_memory=False)\n",
    "loan_all_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see inspect the columns in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_all_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all of our analysis will revolve around loan_status (our target variable), lets see the different values and their proportions in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size\n",
    "sns.set(rc={'figure.figsize':(12,10)})\n",
    "# see proportion of loan status our target variable\n",
    "sns.countplot(loan_all_df.loan_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our goal would be to find differentiating factors between customers who would fully pay vs customer who would default, our observation will come from these two sets of customers in the historic data.  \n",
    "Therefore we can ignore the data where the loan is currently ongoing. We would not know whether these will be fully paid or defaulted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the rows where loan_status is not Current\n",
    "loan_df = loan_all_df.loc[loan_all_df.loan_status != 'Current']\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what is the proportion of charged off customers with respect to Fully paid in the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_df.groupby(\"loan_status\")['loan_status'].agg(['count'])/len(loan_df))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That Fully paid is around 85% and Charged off is around 15%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first do a round of sanity check to remove columns that does not have any information or does not have any variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out percentage of missing values in each column\n",
    "columns = loan_df.columns\n",
    "percent_missing = loan_df.isnull().sum() * 100 / len(loan_df)\n",
    "missing_value_df = pd.DataFrame({'column_name': columns,\n",
    "                                 'percent_missing': percent_missing})\n",
    "missing_value_df.sort_values('percent_missing', ascending = False, inplace=True)\n",
    "\n",
    "# list the columns that have 100% missing values\n",
    "missing_value_df[missing_value_df.percent_missing == 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All those above columns can be deleted as they don't have any information and is not going to help us in the analysis anyways. If business think that any of these columns may have impact to find difference between fully paid and charged off then we are not looking at right sample. Business should be advised to provide right sample set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that have 100% mising values\n",
    "loan_df.drop(columns=list(missing_value_df.loc[missing_value_df.percent_missing == 100,'column_name']),inplace = True)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out numeric columns where there is no variance, i.e. it contains same value in all its rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out columns that have 0 standard deviation\n",
    "loan_df.std()[loan_df.std() == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These columns are not going to help us either"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping column with standard deviation 0\n",
    "loan_df.drop(loan_df.std()[loan_df.std() == 0.0].index.values, axis=1,inplace = True)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets find out non-numeric columns containing single values only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking whether there are columns having single values. Standard deviation check will not work for non-numeric columns\n",
    "uniques = loan_df.apply(lambda x: x.nunique())\n",
    "uniques[uniques==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above non-numeric columns contain single values. Thus not helpful either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns having single values\n",
    "loan_df = loan_df.drop(uniques[uniques==1].index, axis=1)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After understanding the data data definitions from data dictionary we see that following fields will not be available for new customer while applying for loan. Therefore these features cannot be used for finding features.  \n",
    "* `last_credit_pull_d` - The most recent month LC pulled credit for this loan\n",
    "* `last_pymnt_amnt` - Last total payment amount received\n",
    "* `collection_recovery_fee` - post charge off collection fee\n",
    "* `delinq_2yrs` - The number of 30+ days past-due incidences of delinquency in the borrower's credit file for the past 2 years\n",
    "* `mths_since_last_delinq` - The number of months since the borrower's last delinquency.\n",
    "* `last_pymnt_d` - Last month payment was received\n",
    "* `recoveries`  - post charge off gross recovery\n",
    "* `total_pymnt` - Payments received to date for total amount funded\n",
    "* `total_pymnt_inv`- Payments received to date for portion of total amount funded by investors\n",
    "* `total_rec_int` - Interest received to date\n",
    "* `total_rec_late_fee` - Late fees received to date\n",
    "* `total_rec_prncp` - Principal received to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that will not be available at the time of aproving loan\n",
    "columns_to_remove = ['last_credit_pull_d',\n",
    "                     'last_pymnt_amnt',\n",
    "                    'collection_recovery_fee',\n",
    "                     'delinq_2yrs',\n",
    "                     'mths_since_last_delinq',\n",
    "                     'last_pymnt_d',\n",
    "                     'recoveries',\n",
    "                     'total_pymnt',\n",
    "                     'total_pymnt_inv',\n",
    "                     'total_rec_int',\n",
    "                     'total_rec_late_fee',\n",
    "                     'total_rec_prncp'\n",
    "                    ]\n",
    "loan_df.drop(columns_to_remove , axis = 1 , inplace = True)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now find out the columns that have very high unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check potential unique value fields \n",
    "df_colunique = pd.DataFrame(loan_df.nunique()/loan_df.count())\n",
    "# Columns having all unique values excludeing Nulls\n",
    "df_colunique.loc[df_colunique[0] >= 0.99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see these are mostly id columns or free text columns. Therefore we'll not be able to get any pattern form these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns where each row has unique values\n",
    "loan_df.drop(df_colunique.loc[df_colunique[0] >= 0.99].index, axis=1, inplace= True)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Value treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see the missing values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize missing data\n",
    "msno.matrix(loan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above and below graph shows that there missing values the following 4 columns:\n",
    "* `emp_length`\n",
    "* `emp_title`\n",
    "* `title`\n",
    "* `revol_util`\n",
    "* `mths_since_last_record`\n",
    "* `pub_rec_bankruptcies`  \n",
    "Amongst these only `mths_since_last_record` has huge number of missing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(loan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The missingno correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another.  \n",
    "The below heat map shows that `emp_length` and `emp_title` are missing together in 60% cases and `mths_since_last_record` and `pub_rec_bankruptcies` are missing together 50% times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.heatmap(loan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "values = {'emp_length': 'NA', 'emp_title': 'NA', 'title': 'NA',\\\n",
    "          'revol_util': '0%', 'mths_since_last_record': -1, 'pub_rec_bankruptcies':0}\n",
    "loan_df.fillna(value=values, inplace = True)\n",
    "msno.bar(loan_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general we'll first delete and leading and training spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip all columns for leading and lagging spaces\n",
    "loan_df = loan_df.applymap(lambda s : s.strip() if type(s) is str else s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the term field has month as suffix, so we trim that and convert to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove string months from term \n",
    "loan_df.term = loan_df.term.apply(lambda s : s[0:s.index(' ')] if ' ' in s else s)\n",
    "loan_df.term = pd.to_numeric(loan_df.term)\n",
    "loan_df.term.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that int_rate and revol_util field has % as suffix, we remove that and convert to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove % sign from interest rate \n",
    "loan_df.int_rate = loan_df.int_rate.apply(lambda s : s[0:s.index('%')] if '%' in s else s)\n",
    "loan_df.int_rate = pd.to_numeric(loan_df.int_rate)\n",
    "loan_df.int_rate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove % sign from revol_util\n",
    "loan_df.revol_util = loan_df.revol_util.apply(lambda s : s[0:s.index('%')] if '%' in s else s)\n",
    "loan_df.revol_util = pd.to_numeric(loan_df.revol_util)\n",
    "loan_df.revol_util.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df_cat = loan_df.select_dtypes(['object'])\n",
    "# Check potential unique value fields \n",
    "loan_df_cat_colunique = pd.DataFrame(loan_df_cat.nunique()/loan_df_cat.count())\n",
    "# Columns having all unique values excludeing Nulls\n",
    "loan_df_cat_colunique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that following columns either have very high variance or does not add much information\n",
    "* `title`: very high variance\n",
    "* `emp_title`: very high variance\n",
    "* `zip_code`: Not so high variance but lots of values. Addr_state can cover for this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that will can not have any impact\n",
    "columns_to_remove = ['title' , # very high variance\n",
    "                     'emp_title', # very high variance\n",
    "                     'zip_code' # Not so high variance but lots of values where addr_state can cover\n",
    "                    ]\n",
    "loan_df.drop(columns_to_remove , axis = 1 , inplace = True)\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if we have any duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking whether there are duplicate rows\n",
    "loan_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll progress our analysis on the above 26 variables and 38577 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate and segmented univariate analysis on categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is created to do univariate and segmented univariate analysis of categorical variables. This function will accept a data frame having subject column and loan_status column will provide following graphs.\n",
    "* rank frequency plot\n",
    "* bar plot\n",
    "* grouped bar plot\n",
    "* Mosaic plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Univariate Analysis\n",
    "\n",
    "# Write Function to perform univariate analysis on categorical variables \n",
    "\n",
    "def uni_analysis_cat (x , summary = 0, pct_label = True):\n",
    "    print(x.iloc[:,0].describe())\n",
    "    # preparing data for label in mosaic plot\n",
    "    count_table = x.groupby(list(x.columns)).size()#.reset_index(name='counts')\n",
    "    pct_table = count_table.groupby(level=0).apply(lambda x:\n",
    "                                                 round(x / float(x.sum()),2))\\\n",
    "                                    .unstack(fill_value=0)\n",
    "                                \n",
    "    pct_table.index = pct_table.index.map(str)\n",
    "    pct_table = pct_table.stack()\n",
    "   \n",
    "    sns.set(rc={'figure.figsize':(15,6)})\n",
    "    # rank frequency plot\n",
    "    ax = x.iloc[:,0].value_counts().plot(kind='barh')\n",
    "    ax.set(xlabel=\"count\", ylabel=list(x.columns)[0])\n",
    "    plt.show()\n",
    "    f, axes = plt.subplots(1, 2)\n",
    "       \n",
    "    if(~summary):\n",
    "        print('****************************************************************************************************')\n",
    "        # bar plot\n",
    "        sns.countplot( x = x.iloc[:,0], data = x , ax = axes[0])\n",
    "        \n",
    "        # Grouped bar plot\n",
    "        sns.countplot( x = x.iloc[:,0], hue = x.iloc[:,1] , data = x , ax = axes[1] )\n",
    "        \n",
    "        # change label direction\n",
    "        for ax in f.axes:\n",
    "            plt.sca(ax)\n",
    "            plt.xticks(rotation=90)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        \n",
    "        # create proportion labelizer for mosaic plot\n",
    "        if pct_label:\n",
    "            labelizer = lambda k: pct_table.loc[pd.IndexSlice[k[0]],pd.IndexSlice[k[1]],:].values[0]\n",
    "        else:\n",
    "            labelizer = lambda k: ''\n",
    "        \n",
    "        # mosaic plot\n",
    "        mosaic(x.sort_values(list(x.columns)[0]),\n",
    "               list(x.columns),\n",
    "               label_rotation = [90,0], \n",
    "               labelizer=labelizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate and segmented univariate analysis for quantitative variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is created to do univariate and segmented univariate analysis of numeric variables. This function will accept a data frame having subject column and loan_status column will provide following graphs.\n",
    "* box plot\n",
    "* segmented box plot\n",
    "* segmented distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis for quantitative variable \n",
    "\n",
    "\n",
    "def uni_analysis_num (x , type = 'r', log_scale=False):\n",
    "    sns.set(rc={'figure.figsize':(15,6)})\n",
    "    f, axes = plt.subplots(1, 3)\n",
    "    \n",
    "    # print column description\n",
    "    print(round(x.iloc[:,0].describe(),2))\n",
    "\n",
    "    print('****************************************************************************************************')\n",
    "    # for each unique value in 2nd column\n",
    "    for value in list(x.iloc[:,1].unique()):\n",
    "        a = x.loc[x.iloc[:,1] == value,list(x.columns)[0]]\n",
    "        a.rename(index = value, inplace = True)\n",
    "        # kde plot for 1 distribution\n",
    "        p1=sns.kdeplot(a, shade=True)\n",
    "    if log_scale: p1.set_xscale('log')\n",
    "    p1.set_xlabel(list(x.columns)[0])\n",
    "    p1.set_ylabel('Probability')\n",
    "    \n",
    "    # mean indicator marker\n",
    "    meanpointprops = dict(marker='D', markeredgecolor='black',\n",
    "              markerfacecolor='firebrick')\n",
    "    # box plot\n",
    "    bp = sns.boxplot( y = x.iloc[:,0], data = x , ax = axes[0],color = 'g',\n",
    "                     showmeans=True, meanprops=meanpointprops, meanline=False)\n",
    "    if log_scale: bp.set_yscale('log')\n",
    "\n",
    "    # segmented box plot\n",
    "    vp = sns.boxplot( x = x.iloc[:,1] , y = x.iloc[:,0] , data = x , ax = axes[1],\\\n",
    "                     showmeans=True, meanprops=meanpointprops, meanline=False)\n",
    "    #vp = sns.violinplot( x = x.iloc[:,1] , y = x.iloc[:,0] , data = x , ax = axes[1], \\\n",
    "    #               vert = True , inner = 'quartile' ,scale_hue = True )\n",
    "    if log_scale: vp.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bubble Plot to visualise date dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_plot(x , y , z ,percent):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.scatter(x = x\n",
    "                , y = y , \n",
    "                s = percent * 100,\n",
    "                c = 'r',\n",
    "               alpha = 0.8)\n",
    "\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        plt.text(x[i] ,y[i], s= percent[i].round(2) , ha = 'left', va = 'center', fontsize = 12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis for Quantitative variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis : Common function to perform correlation within data frame \n",
    "\n",
    "def bi_analysis_num(df):\n",
    "    sns.set(rc={'figure.figsize':(15,6)})\n",
    "    f, axes = plt.subplots(1, 2)\n",
    "    \n",
    "    #sns.heatmap(df.corr(), fmt='0.2f', annot=True , cmap = 'Greens')\n",
    "    dfc = df.loc[df.loan_status == 'Charged Off']\n",
    "    dff = df.loc[df.loan_status == 'Fully Paid']\n",
    "    \n",
    "    print('The correlation matrix is as below')\n",
    "    print(df.corr())\n",
    "    print('**********************************************************************************')\n",
    "    \n",
    "    sns.kdeplot(dfc.iloc[:,0] , dfc.iloc[:,1] ,  cmap=\"Reds\", shade=True, shade_lowest=False , ax = axes[0])\n",
    "    sns.kdeplot(dff.iloc[:,0] , dff.iloc[:,1] ,  cmap=\"Blues\", shade=True, shade_lowest=False , ax = axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate analysis for Categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis for categorical variables : Common function to perform correlation within data frame \n",
    "\n",
    "def bi_analysis_cat(df):\n",
    "    sns.set(rc={'figure.figsize':(15,6)})\n",
    "   \n",
    "    \n",
    "    ct = pd.crosstab(df.iloc[:,1] , df.iloc[:,2] , margins = True , \\\n",
    "                     margins_name = 'Total' , normalize = True).round(4) * 100\n",
    "    \n",
    "    print('The summary table is as below')\n",
    "    print(ct)\n",
    "    print('**********************************************************************************')\n",
    "       \n",
    "    sns.violinplot( x = df.iloc[:,1] , y = df.iloc[:,0] ,  hue = df.iloc[:,2] , data = df , \\\n",
    "                   vert = True , inner = 'quartile' ,scale_hue = True , split = True , annot = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent t test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is created to perform t test between two numeric distributions. This function will accept two different distributions separately and provide p-value of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform t-test for 2 independent data sets \n",
    "\n",
    "\n",
    "def independant_ttest(x , y ):\n",
    "    stat , p = ss.ttest_ind(x, y , equal_var = False)\n",
    "    #print('t-test stats value =', round(stat, 2))\n",
    "    print('p value = ' , p)\n",
    "    \n",
    "    if ( p < 0.05):\n",
    "        print('The 2 sets of data differ significantly')\n",
    "    else:\n",
    "        print('We cannot state that the 2 sets of data differ significantly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is created to perform chi-squared test between two categorical fields. This function will accept data frame having subject column and loan_status column and provide p-value of for independence test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for a 2 set test using Pearsons's chi2 method\n",
    "\n",
    "\n",
    "def chi2_cat_pearson(df):\n",
    "    ctab = pd.crosstab(df.iloc[:,0] , df.iloc[:,1])\n",
    "    stat , p , dof , expected = ss.chi2_contingency(ctab)\n",
    "    \n",
    "    #print('chi2 stats value is =', round(stat,2))\n",
    "    print('p value =', p)\n",
    "    \n",
    "    if ( p < 0.05):\n",
    "        print('The 2 data sets are not independent of each other ')\n",
    "    else:\n",
    "        print('The 2 data sets are independent of each other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey's HSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tukey's honestly significant difference test (Tukey's HSD) is used to test differences among sample means for significance. The Tukey's HSD tests all pairwise differences while controlling the probability of making one or more Type I errors.  \n",
    "This function will accept data frame having subject column and loan_status column and provide test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for Tukey's HSD check\n",
    "\n",
    "def tukeys_hsd(df, p_value=0.05):\n",
    "    #dta = pd.melt(df, id_vars=list(df.columns)[1], value_vars=list(df.columns)[0])\n",
    "    #print(dta.head())\n",
    "    print(\"Using the pairwise_tukeyhsd Method\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    res2 = pairwise_tukeyhsd(groups= df.iloc[:,1], endog = df.iloc[:,0],  alpha=p_value)\n",
    "    print(\"summary:\", res2.summary())\n",
    "    print(\"mean diffs:\", res2.meandiffs)\n",
    "    print(\"std pairs:\",res2.std_pairs)\n",
    "    print(\"groups unique: \", res2.groupsunique)\n",
    "    print(\"df total:\", res2.df_total)\n",
    "    p_values = psturng(np.abs(res2.meandiffs / res2.std_pairs), len(res2.groupsunique), res2.df_total)\n",
    "    print(\"p values:\", p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared post-hoc test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi2 Post-hoc test is done post chi2 test to investigate pairwise tests further. This will help in finding out the values in subject categorical variable that are most impacting. This performs Bonferroni adjustment on the p-value based on number of multiple pair test which helps in reducing Type-1 errors.  \n",
    "This function will accept data frame having subject column and loan_status column and provide values from subject variable which have significant impact on loan status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_post_hoc(df, p_value = 0.05):\n",
    "    # prepare data for multiple pairwise tests\n",
    "    if df.iloc[:,0].dtypes != 'object':\n",
    "        dummies = pd.get_dummies(df.iloc[:,0],prefix = 'value')\n",
    "    else:\n",
    "        dummies = pd.get_dummies(df.iloc[:,0])\n",
    "    \n",
    "    #dummies.drop(list(dummies.columns)[0],axis= 1, inplace= True)\n",
    "    \n",
    "    adjusted_p = p_value/dummies.shape[1]\n",
    "    print(\"Bonferroni-adjusted p-value: \",adjusted_p)\n",
    "    for series in dummies:\n",
    "        nl = \"\\n\"\n",
    "        \n",
    "        crosstab = pd.crosstab(dummies[f\"{series}\"], df.iloc[:,1])\n",
    "        #print(crosstab, nl)\n",
    "        chi2, p, dof, expected = ss.chi2_contingency(crosstab)\n",
    "        if p < adjusted_p:\n",
    "            print(\"Pairwise comparisons is significant for:\",dummies[f\"{series}\"].name)\n",
    "            print(f\"p-value= {p}{nl}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of consumer attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `addr_state`: The state provided by the borrower in the loan application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['addr_state' , 'loan_status']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mosaic plot shows a lot of variance in fully paid and charged off numbers in different states. NV has the highest proportion (23%) of charged off customers.  \n",
    "Let's check for the significance in chi2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for addr_state\n",
    "chi2_cat_pearson(loan_df[['addr_state','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi2 test says the variable is significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for addr_state\n",
    "chi2_post_hoc(loan_df[['addr_state','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post hoc test confirms the claim. However we this this variable cannot be controlled by Lending Club. Therefore will NOT be considered as one of the most significant drivers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `annual_inc`: The self-reported annual income provided by the borrower during registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['annual_inc', 'loan_status']], log_scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The segmented box plot clearly shows there is variation in median and mean of annual income between Fully paid and charged off segments even in log scale. I.e. in actual scale, the differences will be very significant.  \n",
    "Lets test for statistical significance in difference using t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for annual_income\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].annual_inc ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].annual_inc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-test indicates that the annual income distributions are significantly different for fully paid and charged off segments for significant level 0.05.  \n",
    "We'll now confirm the same using post-hoc test Tukey's HSD with alpha level 0.05 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tukey's HSD for annual_income\n",
    "tukeys_hsd(loan_df[['annual_inc','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above test confirms that we can reject the null hypothesis and from the mean difference we can conclude lower the annual income higher the chances for customer to default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`annual_income` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `verification_status`: Indicates if income was verified by LC, not verified, or if the income source was verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['verification_status', 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mosaic plot shows some variation in fully paid and charged off numbers in different levels of verification status.  \n",
    "Lets test this with chi2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for home_ownership\n",
    "chi2_cat_pearson(loan_df[['verification_status','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chi2 test shows that verification status has impact on loan_status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for verification_status\n",
    "chi2_post_hoc(loan_df[['verification_status','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post-hoc test confirms the claim from chi2 test. However does not make right intuition as verified income has more charged off scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This highlights possible process gap, may be Lending Club should re-look at there income verification process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dti`: A ratio calculated using the borrower’s total monthly debt payments on the total debt obligations, excluding mortgage and the requested LC loan, divided by the borrower’s self-reported monthly income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['dti', 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plot indicates median difference of dti for fully paid and charged off. Mean is also different for these segments but less than median differene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for dti\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].dti ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].dti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-test shows that these 2 distributions are not same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for dti\n",
    "tukeys_hsd(loan_df[['dti','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tukey's HSD confirms the claim. However as we are considering annual income as one of significant variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `emp_length`: Employment length in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['emp_length', 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic plot does not show a lot of variance between fully paid and charged off of different employment years except where the employment length is not provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for emp_length\n",
    "chi2_cat_pearson(loan_df[['emp_length','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi2 test showing that these two variable are not independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for emp_length\n",
    "chi2_post_hoc(loan_df[['emp_length','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post-hoc test confirms the claim. However we don't find this to be very significant specially where employee length is provided. This might mean another process issues. Lending Club should investigate why employee length is not provided. If this is because customer is not employed, then in what grounds loan is getting approved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `home_ownership`: The home ownership status provided by the borrower during registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis of Home ownership and comparison with home status\n",
    "\n",
    "uni_analysis_cat(loan_df[['home_ownership' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for home_ownership\n",
    "\n",
    "chi2_cat_pearson(loan_df[['home_ownership','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for home_ownership\n",
    "chi2_post_hoc(loan_df[['home_ownership','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic plot does not show a lot of variance between fully paid and charged off for different home ownership  statuses even if chi2 and post-hoc states otherwise. We are NOT considering this to be a significant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mths_since_last_record`: The number of months since the last public record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['mths_since_last_record', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for mths_since_last_record\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].mths_since_last_record ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].mths_since_last_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for mths_since_last_record\n",
    "tukeys_hsd(loan_df[['mths_since_last_record','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be same, so distinction cannot be made\n",
    "further, the values are concentrated between 0 and 20.  \n",
    "Even if T test and Tukey's HSD states otherwise, we are NOT considering this to be a significant variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `open_acc`: The number of open credit lines in the borrower's credit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['open_acc', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for open_acc\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].open_acc ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].open_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for open_acc\n",
    "tukeys_hsd(loan_df[['open_acc','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be same, so distinction cannot be made.  \n",
    "This is confirmed by both t test and Tukey's HSD test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `total_acc`: The total number of credit lines currently in the borrower's credit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['total_acc', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for total_acc\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].total_acc ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for total_acc\n",
    "tukeys_hsd(loan_df[['total_acc','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be same, so distinction cannot be made\n",
    "further, the values are concentrated between 0 and 20.  \n",
    "Even if T test and Tukey's HSD states otherwise, we are NOT considering this to be a significant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pub_rec`: Number of derogatory public records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the values are Numeric, we are considering this to be categorical as only 4 values are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Univariate analysis \n",
    "uni_analysis_cat(loan_df[['pub_rec', 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic Plot shows a significant variation between public record 0 and 1 (14% compared to 23% respectively). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for pub_rec\n",
    "chi2_cat_pearson(loan_df[['pub_rec','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi2 test also confirms that pub_rec has significant impact on loan status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for pub_rec\n",
    "chi2_post_hoc(loan_df[['pub_rec','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post-hoc test confirms that, if the Public record is 1 (or more), there is a high propensity to default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`pub_rec` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pub_rec_bankruptcies`: Number of public record bankruptcies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the values are Numeric, we are considering this to be categorical as only 3 values are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Univariate analysis \n",
    "uni_analysis_cat(loan_df[['pub_rec_bankruptcies', 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic Plot shows a significant variation between pub_rec_bankruptcies 0 and 1 (14% compared to 22% respectively). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for pub_rec_bankruptcies\n",
    "chi2_cat_pearson(loan_df[['pub_rec_bankruptcies','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for pub_rec_bankruptcies\n",
    "chi2_post_hoc(loan_df[['pub_rec_bankruptcies','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the pub_rec_bankruptcies record is 1 or more, there is a high propensity to default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`pub_rec_bankruptcies` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll later check for correlation between `pub_rec` and `pub_rec_bankruptcies` to confirm whether we need to keep both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `earliest_cr_line`:\tThe month the borrower's earliest reported credit line was opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This field is in month-year format. we'll split this month and year to analyze this field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of months , perform analysis based on both month and year \n",
    "# start with the setting the date type and then continue with the seperate analysis of Month and year \n",
    "\n",
    "loan_df.earliest_cr_line = pd.to_datetime(loan_df.earliest_cr_line , format = '%b-%y')\n",
    "\n",
    "loan_df['earliest_cr_line_month'] = loan_df.earliest_cr_line.dt.month\n",
    "# need to take care of the years as transformation resulting in future years\n",
    "loan_df['earliest_cr_line_year'] = loan_df.earliest_cr_line.dt.year.apply(lambda x: x-100 if x > 2019 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of month is numeric, but has been considered as categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis considering the month of the earliest credict line \n",
    "uni_analysis_cat(loan_df[['earliest_cr_line_month' , 'loan_status']] , summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# chi2 test for earliest_cr_line_month\n",
    "chi2_cat_pearson(loan_df[['earliest_cr_line_month','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for earliest_cr_line_month\n",
    "chi2_post_hoc(loan_df[['earliest_cr_line_month','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic plot does not show a lot of variance between fully paid and charged off for different home ownership statuses.  \n",
    "Even if chi2 states otherwise, post-hoc test could not identify any particular month as most significant.  \n",
    "we are NOT considering this to be a significant variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis considering the year of earliest credit line \n",
    "# Here we see that delinquency increases witht the later yeas for growth when loans may have increase just to meet the target numbers\n",
    "\n",
    "uni_analysis_cat(loan_df[['earliest_cr_line_year' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for earliest_cr_line_year\n",
    "chi2_cat_pearson(loan_df[['earliest_cr_line_year','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test earliest_cr_line_year\n",
    "chi2_post_hoc(loan_df[['earliest_cr_line_year','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic plot shows that proportion of charged off is continusly increasing post 2004.  Both Chi2 and post hoc test confirms that the variable has significant impact on loan status. However Lending Club will not have direct control on this variable.  \n",
    "However, this can indicate that the process of approving first credit line has deteriorated over due course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of loan attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `loan_amnt`: The listed amount of the loan applied for by the borrower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['loan_amnt' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for loan_amnt\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].loan_amnt ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for loan_amnt\n",
    "tukeys_hsd(loan_df[['loan_amnt' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be same, so distinction cannot be made.  \n",
    "Even if T test and Tukey's HSD states otherwise, we are NOT considering this to be a significant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `installment`: The monthly payment owed by the borrower if the loan originates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['installment' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for installment\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].installment ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].installment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for installment\n",
    "tukeys_hsd(loan_df[['installment','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be same, so distinction cannot be made.  \n",
    "Even if T test and Tukey's HSD states otherwise, we are NOT considering this to be a significant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `int_rate`: Interest Rate on the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['int_rate' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for int_rate\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].int_rate ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].int_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for int_rate\n",
    "tukeys_hsd(loan_df[['int_rate','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median and distribution for fully paid and charged off are significantly different. T-test and Tukey's HSD confirms the claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`int_rate` is one of the most important indicators that Lending club should be interested in. However it is decided based on grade and sub-grade. Hence final significance should be based on significance of grade / sub_grade__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `term`: The number of payments on the loan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "term is a numeric value but has been considered as categorical as it has only 2 possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['term' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for term\n",
    "chi2_cat_pearson(loan_df[['term','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for term\n",
    "chi2_post_hoc(loan_df[['term','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mosaic plot show significant difference in proportion for fully paid and charged off numbers for different terms.  \n",
    "Both ci2 test and post-hoc test indicates the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`term` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `funded_amnt`: The total amount committed to that loan at that point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['funded_amnt', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for funded_amnt\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].funded_amnt ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].funded_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for funded_amnt\n",
    "tukeys_hsd(loan_df[['funded_amnt','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be very similar, so distinction is difficult.\n",
    "Even if T test and Tukey's HSD indicates significant difference in distribution, we are NOT sure regarding the nature of the variable, whether is post loan or pre-loan. We'll take decision on this variable during bi variate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `funded_amnt_inv`: The total amount committed by investors for that loan at that point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['funded_amnt_inv', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for annual_income\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].funded_amnt_inv ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].funded_amnt_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for funded_amnt_inv\n",
    "tukeys_hsd(loan_df[['funded_amnt_inv','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be very similar, so distinction is difficult.\n",
    "Even if T test and Tukey's HSD indicates significant difference in distribution, we are NOT sure regarding the nature of the variable, whether is post loan or pre-loan. We'll take decision on this variable during bi variate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `grade`: LC assigned loan grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['grade', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for grade\n",
    "chi2_cat_pearson(loan_df[['grade','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for grade\n",
    "chi2_post_hoc(loan_df[['grade','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mosaic plot show significant difference in proportion for fully paid and charged off numbers for different terms.  \n",
    "Both ci2 test and post-hoc test indicates the same. Post-hoc test identified all values of grade to be very significant.  \n",
    "\n",
    "However int_rate is decided based on grade and sub grade. - https://www.lendingclub.com/foliofn/rateDetail.action  \n",
    "We shall consider grade and sub-grade as significant variables and not include interest rate which is derived from the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sub_grade`: LC assigned loan subgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['sub_grade' , 'loan_status']] , summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for sub_grade\n",
    "chi2_cat_pearson(loan_df[['sub_grade','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for sub_grade\n",
    "chi2_post_hoc(loan_df[['sub_grade','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mosaic plot show significant difference in proportion for fully paid and charged off numbers for different terms.  \n",
    "Both ci2 test and post-hoc test indicates the same. Post-hoc test identified a number of values of sub-grade to be very significant.  \n",
    "\n",
    "However int_rate is decided based on grade and sub grade. - https://www.lendingclub.com/foliofn/rateDetail.action  \n",
    "We shall consider grade and sub-grade as significant variables and not include interest rate which is derived from the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `purpose`: A category provided by the borrower for the loan request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['purpose' , 'loan_status']] , summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for home_ownership\n",
    "chi2_cat_pearson(loan_df[['purpose','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for purpose\n",
    "chi2_post_hoc(loan_df[['purpose','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mosaic plot show significant difference in proportion for fully paid and charged off numbers for different terms.  \n",
    "Both ci2 test and post-hoc test indicates the same.   \n",
    "We can see that small_business, renewable_energy, educational are purposes where the propensity for default is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`purpose` is an important parameter as it has relevance for Default, we'll consider it as one of the most important variable that Lending Club will be interested in decision making__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `revol_bal`: Total credit revolving balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing Univariate analysis \n",
    "uni_analysis_num(loan_df[['revol_bal', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for revol_bal\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].revol_bal ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].revol_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for revol_bal\n",
    "tukeys_hsd(loan_df[['revol_bal' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be same, so distinction cannot be made. T-test and Tukeu's HSD support the claim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `revol_util`: Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['revol_util' , 'loan_status']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for revol_util\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].revol_util ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].revol_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for revol_util\n",
    "tukeys_hsd(loan_df[['revol_util' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean, median and distribution is significantly different between fully paid and charged off.  \n",
    "The above test confirms that we can reject the null hypothesis and from the mean difference we can conclude higher the revolving debt utilization higher the chances for customer to default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`revol_util` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `issue_d`: The month which the loan was funded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a date variable in month-year form. This will be first split in month and year for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of months , perform analysis based on both month and year \n",
    "# start with the setting the date type and then continue with the seperate analysis of Month and year \n",
    "\n",
    "loan_df.issue_d = pd.to_datetime(loan_df.issue_d , format = '%b-%y')\n",
    "\n",
    "loan_df['issue_d_month'] = loan_df.issue_d.dt.month\n",
    "loan_df['issue_d_year'] = loan_df.issue_d.dt.year\n",
    "\n",
    "#Compress the data for the issue date to display the same in the consolidated form based on % \n",
    "\n",
    "df_issue_d = loan_df.loc[loan_df.loan_status == 'Charged Off' , ['issue_d_year' , 'issue_d_month' , 'loan_status']]\\\n",
    "            .groupby(['issue_d_year' , 'issue_d_month' , 'loan_status']).size().reset_index()\n",
    "\n",
    "df_issue_d['status_percent'] = (df_issue_d[0]/sum(df_issue_d[0])).round(4)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "month is a numeric values but treated as ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis considering the month of the loan issue \n",
    "# Here we see that delinquency increases witht the later months when loans may have increase just to meet the target numbers\n",
    "\n",
    "uni_analysis_cat(loan_df[['issue_d_month' , 'loan_status']] , summary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for issue_d_month\n",
    "chi2_cat_pearson(loan_df[['issue_d_month','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for issue_d_month\n",
    "chi2_post_hoc(loan_df[['issue_d_month','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic plot does not show a lot of variance between fully paid and charged off for different issue month.  \n",
    "Even if chi2 and post-hoc states otherwise, we are NOT considering this to be a significant variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis considering the year of the loan issue \n",
    "uni_analysis_cat(loan_df[['issue_d_year' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for issue_d_year\n",
    "chi2_cat_pearson(loan_df[['issue_d_year','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for issue_d_year\n",
    "chi2_post_hoc(loan_df[['issue_d_year','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosaic plot shows that proportion of charged off is higher in 2007, 2008 and 2011.  Both Chi2 and post hoc test confirms that the variable has significant impact on loan status. However Lending Club will not have direct control on this variable.  \n",
    "However, this can indicate that the process of issuing loan is not always efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undertake the scatter plot for the charged Off variables\n",
    "\n",
    "bubble_plot(df_issue_d.issue_d_month , df_issue_d.issue_d_year , df_issue_d.loan_status , df_issue_d.status_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that delinquency increases witht the later yeas for growth when loans may have increase just to meet the target numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `inq_last_6mths`: The number of inquiries in past 6 months (excluding auto and mortgage inquiries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is numeric, but treated as categorical as there are only 8 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_cat(loan_df[['inq_last_6mths' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for inq_last_6mths\n",
    "chi2_cat_pearson(loan_df[['inq_last_6mths','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for inq_last_6mths\n",
    "chi2_post_hoc(loan_df[['inq_last_6mths','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mosaic plot show significant difference in proportion for fully paid and charged off numbers for different levels of inquiries.  \n",
    "\n",
    "Both ci2 test and post-hoc test indicates the same. post hoc test indicates value greater that risk has potential risk for delinquency. This can be used by Lending Club to assess risk of delinquency.\n",
    "\n",
    "  As not a lot of customers may do an enquiry with Lending Club, this data may not be always availible completely to make a decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derived Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly income - binned "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the derived variable is create bins for monthly income can visualize the same as categorical variable and the establish the same claim that annual income is one of the most significant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual income to monthly income\n",
    "loan_df['monthly_inc'] =  loan_df.annual_inc/12\n",
    "loan_df['monthly_inc'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins to be created\n",
    "bins = [300, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 50000, 500000]\n",
    "# bin labels\n",
    "labels = ['300-1000', \n",
    "          '1000-2000', \n",
    "          '2000-3000', \n",
    "          '3000-4000', \n",
    "          '4000-5000', \n",
    "          '5000-6000', \n",
    "          '6000-7000', \n",
    "          '7000-8000', \n",
    "          '8000-9000', \n",
    "          '9000-10000', \n",
    "          '10000-50000', \n",
    "          '50000-500000']\n",
    "loan_df['monthly_inc_bins'] =  pd.cut(loan_df.monthly_inc, bins = bins, labels=labels)\n",
    "uni_analysis_cat(loan_df[['monthly_inc_bins', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 test for monthly_inc_bins\n",
    "chi2_cat_pearson(loan_df[['monthly_inc_bins','loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi2 post-hoc test for issue_d_year\n",
    "chi2_post_hoc(loan_df[['monthly_inc_bins','loan_status']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mosaic plots, chi2 test and post hoc test confirms that monthly income bins and in turn annual income as significant impact of delinquency. There is no need to select this variable as this derived from annual income straightway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Amount as Percentage of Annual Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# % of loan amount with respect to annual inc\n",
    "loan_df['loan_amount_by_annual_inc'] = loan_df.loan_amnt/loan_df.annual_inc*100\n",
    "uni_analysis_num(loan_df[['loan_amount_by_annual_inc', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for loan_amount_by_annual_inc\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].loan_amount_by_annual_inc ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].loan_amount_by_annual_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for loan_amount_by_annual_inc\n",
    "tukeys_hsd(loan_df[['loan_amount_by_annual_inc','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean, median and distribution is significantly different between fully paid and charged off.  \n",
    "The above test confirms that we can reject the null hypothesis and from the mean difference we can conclude higher the ratio between loan_amount and annual_inc higher the chances for customer to default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`loan_amount_by_annual_inc` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Installment as Percentage of Annual Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % of loan installment with respect to monthly income\n",
    "loan_df['annual_installment_by_annual_inc'] = ((loan_df.installment * 12)/loan_df.annual_inc)*100\n",
    "uni_analysis_num(loan_df[['annual_installment_by_annual_inc', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for annual_installment_by_annual_inc\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].annual_installment_by_annual_inc ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].annual_installment_by_annual_inc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for annual_installment_by_annual_inc\n",
    "tukeys_hsd(loan_df[['annual_installment_by_annual_inc','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean, median and distribution is significantly different between fully paid and charged off.  \n",
    "The above test confirms that we can reject the null hypothesis and from the mean difference we can conclude higher the ratio between annual installment and annual_inc higher the chances for customer to default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`annual_installment_by_annual_inc` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surplus amount per month without considering current loan installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surplus amount per month without considering current loan installment\n",
    "loan_df['surplus_amount_per_month'] = (1 - (loan_df.dti/100)) * loan_df.annual_inc/12\n",
    "uni_analysis_num(loan_df[['surplus_amount_per_month', 'loan_status']], log_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for surplus_amount_per_month\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].surplus_amount_per_month ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].surplus_amount_per_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for surplus_amount_per_month\n",
    "tukeys_hsd(loan_df[['surplus_amount_per_month','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean, median and distribution is significantly different between fully paid and charged off.  \n",
    "The above test confirms that we can reject the null hypothesis and from the mean difference we can conclude lesser the surplus amount higher the chances for customer to default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__`surplus_amount_per_month` is one of the most important variables that Lending club should be interested in to make the decision__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funded amount as proportion to Loan amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_df['funded_amnt_by_loan_amnt'] = loan_df.funded_amnt/loan_df.loan_amnt\n",
    "uni_analysis_num(loan_df[['funded_amnt_by_loan_amnt', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for funded_amnt_by_loan_amnt\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].funded_amnt_by_loan_amnt ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].funded_amnt_by_loan_amnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for funded_amnt_by_loan_amnt\n",
    "tukeys_hsd(loan_df[['funded_amnt_by_loan_amnt','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spread for fully paid and charged off loans seams to be same, distinction is difficult.  \n",
    "Even if T test and Tukey's HSD states otherwise, we are NOT considering this to be a significant variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open_acc in proportion of total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derived matrix based on open_acc and total_acc\n",
    "loan_df['open_acc_by_total_acc'] = loan_df.open_acc/loan_df.total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_analysis_num(loan_df[['open_acc_by_total_acc', 'loan_status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent T test for open_acc_by_total_acc\n",
    "independant_ttest(loan_df[loan_df.loan_status == \"Charged Off\"].open_acc_by_total_acc ,\\\n",
    "                  loan_df[loan_df.loan_status == \"Fully Paid\"].open_acc_by_total_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD for open_acc_by_total_acc\n",
    "tukeys_hsd(loan_df[['open_acc_by_total_acc','loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derived matrix open_acc_by_total_acc suggest nothing in particular, as distribution is similar to open_acc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now perform correlation analysis on all numeric values including the derived metrics. This will also include numeric variables that have been considered as categorical for univariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is correlation plot for all numeric variables\n",
    "sns.heatmap(loan_df.corr(), cmap = sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_df.corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to read the complete matrix, so we'll create smaller correlation matrix with only the variables which have correlation value more than 0.5 with at least another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns where they have absolute correlation greater than 0.5 with some other column\n",
    "corr_matrix = loan_df.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_keep_col = [column for column in upper.columns if any(upper.loc[:,column] >=0.5)]\n",
    "to_keep_row = [row for row in upper.index if any(upper.loc[row,:] >=0.5)]\n",
    "to_keep = list(set(to_keep_col).union(set(to_keep_row)))\n",
    "to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Focus on these highly correlated columns to derive new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset dataframe on highly correlated columns\n",
    "loan_high_corr_df = loan_df.loc[:,to_keep]\n",
    "sns.heatmap(loan_high_corr_df.corr(),cmap =sns.cm.rocket_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_high_corr_df.corr().style.background_gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us following list of highly correlated variables from our earlier identified most important variables.\n",
    "* `annual_inc` - `surplus_amount_per_month`: consider any of these in important list of variables\n",
    "* `loan_amount_by_annual_inc` - `annual_installment_by_annual_inc`: consider any of these in important list of variables\n",
    "* `pub_rec_bankruptcies` - `pub_rec`: consider any of these in important list of variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Int_rate vs DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Finding the correlation between the interest rate and the dti for loans which are paid and charged off\n",
    "\n",
    "bi_analysis_num(loan_df[['int_rate' , 'dti' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we observe that at same level of dti , if the loan has a higher interest rate ,there are high chances of default "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTI vs purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis of dti and purpose\n",
    "\n",
    "bi_analysis_cat(loan_df[['dti' , 'purpose' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose for which loan is applied does indicate some chances for default. Some of the purposes have been identified as more risky ventures as compared to others . Analysing purpose alongwith dti, we see that loans taken for car , small business , home improvement are risky even at lower dti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dti vs home ownership "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_analysis_cat(loan_df[['dti' , 'home_ownership' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of home ownership do not show any significant difference on the final loan status. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dt vs inquiries in the last 6 months to understanding the availablity background information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the relation between dti and enquiries in last 6 months \n",
    "\n",
    "print(loan_df[['dti' , 'inq_last_6mths']].corr())\n",
    "\n",
    "bi_analysis_cat(loan_df[['dti' , 'inq_last_6mths' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As number of inquiries for loan increase the possibility to default at lower dti increases . Thus number of inquiries is a good leading indicator for the tendency to borrow and default even with lower dtis. However since the correlation between inquiries and dti is low , it does not indicate a 'credit seeking tendency'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funded amount invested vs past bankruptcies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loan_df[['funded_amnt_inv' , 'inq_last_6mths']].corr())\n",
    "\n",
    "print('**************************************************************************************************')\n",
    "\n",
    "bi_analysis_cat(loan_df[['funded_amnt_inv' , 'pub_rec_bankruptcies' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between funded amount invested and number of bankrupties is very low. Thus the members who invest in loan do not have enough information about the past bankrupties. \n",
    "\n",
    "Past bankruptcy is an established indicator of default . Transfer of the infromation to the investors can reduce the investment in risky loans "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funded amount vs dti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_analysis_num(loan_df[['funded_amnt_inv' , 'dti' , 'loan_status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that Information of the dti not available to the investors since higher dti should ideally reduce the investment in the loan and thus serve as a leadfing indicator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis concludes that following are the most important variables that Lending Club should be interested in while making decision regarding loan approval.\n",
    "* Customer Variable\n",
    "    1. `annual_inc`\n",
    "    2. `pub_rec` / `pub_rec_bankruptcies`\n",
    "* Loan Variable\n",
    "    3. `grade` / `sub_grade` (We are not considering int_rate anymore)\n",
    "    4. `term`\n",
    "    5. `revol_utl`\n",
    "* Derived variable\n",
    "    6. `annual_installment_by_annual_inc` / `loan_amount_by_annual_inc`\n",
    "    7. `surplus_amount_per_month`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
